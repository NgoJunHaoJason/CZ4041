{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit0656ffb61a14454b8758eedef206058e",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle challenge - IEEE-CIS Fraud Detection\n",
    "\n",
    "based on [this notebook](https://www.kaggle.com/kabure/extensive-eda-and-modeling-xgb-hyperopt) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "data:\n['sample_submission.csv',\n 'train_transaction.csv',\n 'test_identity.csv',\n 'train_identity.csv',\n 'test_transaction.csv']\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\n",
    "from functools import partial\n",
    "\n",
    "import os\n",
    "import gc\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "print('data:')\n",
    "pprint(os.listdir('data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = pd.read_csv('data/train_identity.csv')\n",
    "transaction_df = pd.read_csv('data/train_transaction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_table(data_frame):\n",
    "    \"\"\"\n",
    "    data_frame (pd.DataFrame): the data frame to get a summary of\n",
    "\n",
    "    returns\n",
    "    summary (pd.DataFrame): the summary of the data frame passed in\n",
    "    \"\"\"\n",
    "    print(f'Dataset Shape: {data_frame.shape}')\n",
    "\n",
    "    summary = pd.DataFrame(data_frame.dtypes, columns=['dtypes'])\n",
    "    summary = summary.reset_index()\n",
    "\n",
    "    summary['Name'] = summary['index']\n",
    "    summary = summary[['Name', 'dtypes']]\n",
    "\n",
    "    summary['Missing'] = data_frame.isnull().sum().values\n",
    "    summary['Uniques'] = data_frame.nunique().values\n",
    "    summary['First Value'] = data_frame.loc[0].values\n",
    "    summary['Second Value'] = data_frame.loc[1].values\n",
    "    summary['Third Value'] = data_frame.loc[2].values\n",
    "\n",
    "    for name in summary['Name'].value_counts().index:\n",
    "        summary.loc[summary['Name'] == name, 'Entropy'] = round(\n",
    "            stats.entropy(data_frame[name].value_counts(normalize=True), base=2),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def reduce_mem_usage(data_frame, verbose=True):\n",
    "    numeric_types = [\n",
    "        'int16',\n",
    "        'int32',\n",
    "        'int64',\n",
    "        'float16',\n",
    "        'float32',\n",
    "        'float64',\n",
    "    ]\n",
    "\n",
    "    start_mem = data_frame.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for column in data_frame.columns:\n",
    "        column_type = data_frame[column].dtypes\n",
    "\n",
    "        if column_type in numeric_types:\n",
    "            column_min = data_frame[column].min()\n",
    "            column_max = data_frame[column].max()\n",
    "\n",
    "            if str(column_type)[:3] == 'int':\n",
    "                if column_min > np.iinfo(np.int8).min and column_max < np.iinfo(np.int8).max:\n",
    "                    data_frame[column] = data_frame[column].astype(np.int8)\n",
    "\n",
    "                elif column_min > np.iinfo(np.int16).min and column_max < np.iinfo(np.int16).max:\n",
    "                    data_frame[column] = data_frame[column].astype(np.int16)\n",
    "\n",
    "                elif column_min > np.iinfo(np.int32).min and column_max < np.iinfo(np.int32).max:\n",
    "                    data_frame[column] = data_frame[column].astype(np.int32)\n",
    "\n",
    "                elif column_min > np.iinfo(np.int64).min and column_max < np.iinfo(np.int64).max:\n",
    "                    data_frame[column] = data_frame[column].astype(np.int64)\n",
    "\n",
    "            else:  # column data type is float\n",
    "                if column_min > np.finfo(np.float16) and column_max < np.finfo(np.float16).max:\n",
    "                    data_frame[column] = data_frame[column].astype(np.float16)\n",
    "\n",
    "                "
   ]
  }
 ]
}