{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do hyperparameter tuning \n",
    "\n",
    "- for Light Gradient Boosting Machine\n",
    "- [LightGBM parameters](https://lightgbm.readthedocs.io/en/latest/Parameters.html)\n",
    "- [tuning LightGBM](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html)\n",
    "- [optuna sample](https://github.com/optuna/optuna/blob/master/examples/lightgbm_simple.py)\n",
    "- [optuna trial](https://optuna.readthedocs.io/en/stable/reference/trial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "import joblib\n",
    "import multiprocessing\n",
    "import optuna\n",
    "import os\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "model_dir_path = 'models/lgbm/'\n",
    "output_dir_path = 'output/lgbm/'\n",
    "\n",
    "train_transaction_data_path = 'data/train_transaction.csv'\n",
    "train_identity_data_path = 'data/train_identity.csv'\n",
    "test_transaction_data_path = 'data/test_transaction.csv'\n",
    "test_identity_data_path = 'data/test_identity.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define utility function to reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Reduce dataframe size\n",
    "\n",
    "    params:\n",
    "    - df: dataframe to reduce the size of\n",
    "\n",
    "    return:\n",
    "    - dataframe of reduced size\n",
    "    \"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'float128']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float64).min and c_max < np.finfo(np.float64).max:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "                elif c_min > np.finfo(np.float128).min and c_max < np.finfo(np.float128).max:\n",
    "                    df[col] = df[col].astype(np.float128)\n",
    "                    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    if verbose: \n",
    "        print(\n",
    "            'Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(\n",
    "            end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "        ))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list down useless features (known from feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_features = [\n",
    "    'TransactionID',  # not really a feature\n",
    "    'dist2',  # transaction features\n",
    "    'C3',  # C features\n",
    "    'D6', 'D7', 'D8', 'D9', 'D12', 'D13', 'D14',  # D features\n",
    "    'M1',  # M features\n",
    "    'id_07', 'id_08', 'id_18', 'id_21', 'id_22', 'id_23',  # id features\n",
    "    'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_35',  # id features\n",
    "    'V6', 'V8', 'V9', 'V10', 'V11', 'V14', 'V15', 'V16',  # V features\n",
    "    'V18', 'V21', 'V22', 'V27', 'V28', 'V31', 'V32',  # V features\n",
    "    'V41', 'V42', 'V46', 'V50', 'V51', 'V59', 'V65',  # V features\n",
    "    'V68', 'V71', 'V72', 'V79', 'V80', 'V84', 'V85',  # V features\n",
    "    'V88', 'V89', 'V92', 'V93', 'V95', 'V98', 'V101',  # V features\n",
    "    'V104', 'V106', 'V107', 'V108', 'V109', 'V110',  # V features\n",
    "    'V111', 'V112', 'V113', 'V114', 'V116', 'V117',  # V features\n",
    "    'V118', 'V119', 'V120', 'V121', 'V122', 'V123',  # V features \n",
    "    'V125', 'V138', 'V141', 'V142', 'V144', 'V146',  # V features \n",
    "    'V147', 'V148', 'V151', 'V153', 'V154', 'V155',  # V features \n",
    "    'V157', 'V158', 'V159', 'V161', 'V163', 'V164',  # V features \n",
    "    'V166', 'V172', 'V173', 'V174', 'V175', 'V176',  # V features \n",
    "    'V177', 'V178', 'V179', 'V180', 'V181', 'V182',  # V features  \n",
    "    'V183', 'V184', 'V185', 'V186', 'V190', 'V191',  # V features  \n",
    "    'V192', 'V193', 'V194', 'V195', 'V196', 'V197',  # V features  \n",
    "    'V198', 'V199', 'V214', 'V216', 'V220', 'V225',  # V features \n",
    "    'V226', 'V227', 'V230', 'V233', 'V235', 'V236',  # V features  \n",
    "    'V237', 'V238', 'V239', 'V240', 'V241', 'V242',  # V features \n",
    "    'V244', 'V246', 'V247', 'V248', 'V249', 'V250',  # V features \n",
    "    'V252', 'V254', 'V255', 'V269', 'V276', 'V297',  # V features \n",
    "    'V300', 'V302', 'V304', 'V305', 'V325', 'V327',  # V features  \n",
    "    'V328', 'V329', 'V330', 'V334', 'V335', 'V336',  # V features \n",
    "    'V337', 'V338', 'V339',  # V features \n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function to disregard OS versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_os_version(df, verbose: bool=True):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    - df (DataFrame): has id_30 as one of its columns\n",
    "    - verbose (bool): prints information if True\n",
    "\n",
    "    return: dataframe, after os versions have been ignored\n",
    "    \"\"\"\n",
    "    os_list = [\n",
    "        'Android',\n",
    "        'iOS',\n",
    "        'Mac OS X',\n",
    "        'Windows',\n",
    "    ]\n",
    "\n",
    "    for index, operating_system in df.id_30.iteritems():\n",
    "        new_os = 'other'\n",
    "\n",
    "        if isinstance(operating_system, str):\n",
    "            for known_os in os_list:\n",
    "                if known_os in operating_system:\n",
    "                    new_os = known_os\n",
    "                    break\n",
    "\n",
    "        df.at[index, 'id_30'] = new_os\n",
    "\n",
    "    if verbose:\n",
    "        print('operating systems:', df.id_30.unique())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function to disregard browser versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_browser_version(df, verbose: bool=True):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    - df (DataFrame): has id_31 as one of its columns\n",
    "    - verbose (bool): prints information if True\n",
    "\n",
    "    return: dataframe, after browser versions have been ignored\n",
    "    \"\"\"\n",
    "    browser_list = [\n",
    "        'aol',\n",
    "        'chrome',\n",
    "        'chromium',\n",
    "        'comodo',\n",
    "        'cyberfox',\n",
    "        'edge',\n",
    "        'firefox',\n",
    "        'icedragon',\n",
    "        'ie',\n",
    "        'iron',\n",
    "        'maxthon',\n",
    "        'opera',\n",
    "        'palemoon',\n",
    "        'puffin',\n",
    "        'safari',\n",
    "        'samsung',\n",
    "        'seamonkey',\n",
    "        'silk',\n",
    "        'waterfox',\n",
    "    ]\n",
    "\n",
    "    for index, browser in df.id_31.iteritems():\n",
    "        new_browser = 'other'\n",
    "\n",
    "        if isinstance(browser, str):\n",
    "            for known_browser in browser_list:\n",
    "                if known_browser in browser:\n",
    "                    new_browser = known_browser\n",
    "                    break\n",
    "\n",
    "        df.at[index, 'id_31'] = new_browser\n",
    "\n",
    "    if verbose:\n",
    "        print('browsers:', df.id_31.unique())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function for preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, verbose: bool=True):\n",
    "    \"\"\"\n",
    "    Does the following preprocessing steps:\n",
    "    - disregard os versions\n",
    "    - disregard browser versions\n",
    "    - drop useless features\n",
    "    - convert object columns to string columns\n",
    "    - imputation (for numbers, fill with interquartile mean)\n",
    "    - do label encoding for non-numeric values\n",
    "    - reduce memory usage again\n",
    "\n",
    "    params:   \n",
    "    - df (DataFrame): dataframe to preprocess (has columns id_30 and id_31)\n",
    "    - verbose (bool): prints information if True\n",
    "\n",
    "    return: dataframe, preprocessing is complete\n",
    "    \"\"\"\n",
    "    df = df.drop(useless_features, axis=1)\n",
    "    df = ignore_os_version(df, verbose)\n",
    "    df = ignore_browser_version(df, verbose)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column]= df[column].astype(str)\n",
    "            df[column] = le.fit_transform(df[column])\n",
    "        else:\n",
    "            df[column] = df[column].fillna(df[column].quantile().mean())\n",
    "\n",
    "    df = reduce_mem_usage(df, verbose)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and preprocess training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mem. usage decreased to 542.35 Mb (69.4% reduction)\nMem. usage decreased to 25.86 Mb (42.7% reduction)\nnumber of rows in training data: 590540\noperating systems:['other' 'Android' 'iOS' 'Mac OS X' 'Windows']\nbrowsers:['other' 'samsung' 'safari' 'chrome' 'edge' 'firefox' 'ie' 'opera' 'aol'\n 'silk' 'waterfox' 'puffin' 'cyberfox' 'palemoon' 'maxthon' 'iron'\n 'seamonkey' 'comodo' 'chromium' 'icedragon']\nMem. usage decreased to 357.35 Mb (22.1% reduction)\nCPU times: user 1min 17s, sys: 46.3 s, total: 2min 4s\nWall time: 2min 5s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   isFraud  TransactionDT  TransactionAmt  ProductCD  card1  card2  card3  \\\n0        0          86400            68.5          4  13926  361.0  150.0   \n1        0          86401            29.0          4   2755  404.0  150.0   \n2        0          86469            59.0          4   4663  490.0  150.0   \n3        0          86499            50.0          4  18132  567.0  150.0   \n4        0          86506            50.0          1   4497  514.0  150.0   \n\n   card4  card5  card6  ...  id_30  id_31  id_32  id_33  id_34  id_36  id_37  \\\n0      1  142.0      1  ...      4     12   24.0    260      4      2      2   \n1      2  102.0      1  ...      4     12   24.0    260      4      2      2   \n2      4  166.0      2  ...      4     12   24.0    260      4      2      2   \n3      2  117.0      2  ...      4     12   24.0    260      4      2      2   \n4      2  102.0      1  ...      0     16   32.0    164      3      0      1   \n\n   id_38  DeviceType  DeviceInfo  \n0      2           2        1742  \n1      2           2        1742  \n2      2           2        1742  \n3      2           2        1742  \n4      1           1         954  \n\n[5 rows x 270 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isFraud</th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>ProductCD</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card4</th>\n      <th>card5</th>\n      <th>card6</th>\n      <th>...</th>\n      <th>id_30</th>\n      <th>id_31</th>\n      <th>id_32</th>\n      <th>id_33</th>\n      <th>id_34</th>\n      <th>id_36</th>\n      <th>id_37</th>\n      <th>id_38</th>\n      <th>DeviceType</th>\n      <th>DeviceInfo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>86400</td>\n      <td>68.5</td>\n      <td>4</td>\n      <td>13926</td>\n      <td>361.0</td>\n      <td>150.0</td>\n      <td>1</td>\n      <td>142.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>86401</td>\n      <td>29.0</td>\n      <td>4</td>\n      <td>2755</td>\n      <td>404.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>102.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>86469</td>\n      <td>59.0</td>\n      <td>4</td>\n      <td>4663</td>\n      <td>490.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>166.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>86499</td>\n      <td>50.0</td>\n      <td>4</td>\n      <td>18132</td>\n      <td>567.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>117.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>86506</td>\n      <td>50.0</td>\n      <td>1</td>\n      <td>4497</td>\n      <td>514.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>102.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>16</td>\n      <td>32.0</td>\n      <td>164</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>954</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 270 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transaction_dataframe = pd.read_csv(train_transaction_data_path)\n",
    "transaction_dataframe = reduce_mem_usage(transaction_dataframe)\n",
    "\n",
    "identity_dataframe = pd.read_csv(train_identity_data_path)\n",
    "identity_dataframe = reduce_mem_usage(identity_dataframe)\n",
    "\n",
    "dataframe = transaction_dataframe.merge(identity_dataframe, how='outer')\n",
    "\n",
    "del transaction_dataframe\n",
    "del identity_dataframe\n",
    "\n",
    "print(f'number of rows in training data: {len(dataframe)}')\n",
    "dataframe = preprocess(dataframe)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dataframe = dataframe.drop('isFraud', axis=1)\n",
    "is_fraud_data = dataframe['isFraud']\n",
    "\n",
    "del dataframe\n",
    "\n",
    "train_features, val_features, train_target, val_target = train_test_split(\n",
    "    features_dataframe, \n",
    "    is_fraud_data, \n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "del features_dataframe\n",
    "del is_fraud_data\n",
    "\n",
    "train_data = lgb.Dataset(train_features, train_target)\n",
    "val_data = lgb.Dataset(val_features, val_target)\n",
    "\n",
    "del train_features\n",
    "del train_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'feature_pre_filter': False,\n",
    "        'seed': 0,\n",
    "        'early_stopping_round': 500,\n",
    "        'num_iterations': 10000,\n",
    "        'boosting': 'gbdt',  # gbdt > dart; don't know about goss\n",
    "\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 500, 1500),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 60, 400),\n",
    "        \n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.6, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 40, 120),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.6, 1.0),\n",
    "\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.001, 0.01),\n",
    "        \n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 1.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 1.0),\n",
    "        'min_split_gain': trial.suggest_loguniform('min_split_gain', 1e-8, 1.0),\n",
    "    }\n",
    "\n",
    "    classifier = lgb.train(\n",
    "        params, \n",
    "        train_data,\n",
    "        valid_sets=[val_data],\n",
    "        verbose_eval=1000,\n",
    "    )\n",
    "\n",
    "    prediction = classifier.predict(val_features)\n",
    "    auc = roc_auc_score(val_target, prediction)\n",
    "\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training until validation scores don't improve for 200 rounds\n[200]\tvalid_0's auc: 0.924497\n[400]\tvalid_0's auc: 0.941908\n[600]\tvalid_0's auc: 0.954546\n[800]\tvalid_0's auc: 0.960576\n[1000]\tvalid_0's auc: 0.964565\nDid not meet early stopping. Best iteration is:\n[1000]\tvalid_0's auc: 0.964565\n[I 2020-04-25 21:04:06,305] Finished trial#0 with value: 0.9645650987258862 with parameters: {'num_leaves': 1040, 'min_data_in_leaf': 358, 'bagging_fraction': 0.7703481420471794, 'bagging_freq': 98, 'feature_fraction': 0.8389227182789362, 'learning_rate': 0.007559609240538312, 'lambda_l1': 4.8604898170842596e-05, 'lambda_l2': 0.007854110557444867, 'min_split_gain': 0.0004277591361417998}. Best is trial#0 with value: 0.9645650987258862.\nTraining until validation scores don't improve for 200 rounds\n[200]\tvalid_0's auc: 0.939898\n[400]\tvalid_0's auc: 0.959812\n[600]\tvalid_0's auc: 0.966426\n[800]\tvalid_0's auc: 0.968473\n[1000]\tvalid_0's auc: 0.969813\nDid not meet early stopping. Best iteration is:\n[1000]\tvalid_0's auc: 0.969813\n[I 2020-04-25 21:10:28,913] Finished trial#1 with value: 0.9698127149378203 with parameters: {'num_leaves': 907, 'min_data_in_leaf': 67, 'bagging_fraction': 0.7959407614045418, 'bagging_freq': 35, 'feature_fraction': 0.8373995481738198, 'learning_rate': 0.008855813036419798, 'lambda_l1': 0.00011282186096906252, 'lambda_l2': 2.5330949375827356e-05, 'min_split_gain': 2.385984130703574e-08}. Best is trial#1 with value: 0.9698127149378203.\nTraining until validation scores don't improve for 200 rounds\n[200]\tvalid_0's auc: 0.924765\n[400]\tvalid_0's auc: 0.941656\n[600]\tvalid_0's auc: 0.953944\n[800]\tvalid_0's auc: 0.959742\n[1000]\tvalid_0's auc: 0.962837\nDid not meet early stopping. Best iteration is:\n[1000]\tvalid_0's auc: 0.962837\n[I 2020-04-25 21:15:10,607] Finished trial#2 with value: 0.9628365652521306 with parameters: {'num_leaves': 639, 'min_data_in_leaf': 177, 'bagging_fraction': 0.6115343970772743, 'bagging_freq': 116, 'feature_fraction': 0.9684767589809927, 'learning_rate': 0.0072134586834418125, 'lambda_l1': 0.195094208610328, 'lambda_l2': 0.00043121119292131437, 'min_split_gain': 0.0020007695940961936}. Best is trial#1 with value: 0.9698127149378203.\nTraining until validation scores don't improve for 200 rounds\n[200]\tvalid_0's auc: 0.934395\n[400]\tvalid_0's auc: 0.955076\n[600]\tvalid_0's auc: 0.964567\n[800]\tvalid_0's auc: 0.968192\n[1000]\tvalid_0's auc: 0.970118\nDid not meet early stopping. Best iteration is:\n[1000]\tvalid_0's auc: 0.970118\n[I 2020-04-25 21:22:32,733] Finished trial#3 with value: 0.9701179618768726 with parameters: {'num_leaves': 1514, 'min_data_in_leaf': 322, 'bagging_fraction': 0.9771827806771647, 'bagging_freq': 81, 'feature_fraction': 0.9783725268375856, 'learning_rate': 0.009410342266746773, 'lambda_l1': 6.282281464176891e-07, 'lambda_l2': 1.69215296516555e-05, 'min_split_gain': 1.0471785772254511e-05}. Best is trial#3 with value: 0.9701179618768726.\nTraining until validation scores don't improve for 200 rounds\n[200]\tvalid_0's auc: 0.919201\n[400]\tvalid_0's auc: 0.927912\n[600]\tvalid_0's auc: 0.93585\n[800]\tvalid_0's auc: 0.943469\n[1000]\tvalid_0's auc: 0.950497\nDid not meet early stopping. Best iteration is:\n[1000]\tvalid_0's auc: 0.950497\n[I 2020-04-25 21:27:58,185] Finished trial#4 with value: 0.9504967971325768 with parameters: {'num_leaves': 1532, 'min_data_in_leaf': 302, 'bagging_fraction': 0.8245336283155155, 'bagging_freq': 32, 'feature_fraction': 0.756970895323702, 'learning_rate': 0.003433296315951511, 'lambda_l1': 0.003556244751257972, 'lambda_l2': 0.000512604090357778, 'min_split_gain': 2.4085176879814463e-06}. Best is trial#3 with value: 0.9701179618768726.\nCPU times: user 5h 27min 35s, sys: 4min 32s, total: 5h 32min 7s\nWall time: 29min 18s\n"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show optimisation information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of finished trials: 5\nBest trial:\n  Value: 0.9701179618768726\n  Params:\n    num_leaves: 1514\n    min_data_in_leaf: 322\n    bagging_fraction: 0.9771827806771647\n    bagging_freq: 81\n    feature_fraction: 0.9783725268375856\n    learning_rate: 0.009410342266746773\n    lambda_l1: 6.282281464176891e-07\n    lambda_l2: 1.69215296516555e-05\n    min_split_gain: 1.0471785772254511e-05\n"
    }
   ],
   "source": [
    "print(f'Number of finished trials: {len(study.trials)}')\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f'  Value: {trial.value}')\n",
    "\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/lgbm/lgbm_1.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(booster, model_dir_path + 'lgbm_2.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and preprocess test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 472.59 Mb (68.9% reduction)\n",
      "Mem. usage decreased to 25.44 Mb (42.7% reduction)\n",
      "number of rows in test data: 506691\n",
      "operating systems:['other' 'Android' 'iOS' 'Windows' 'Mac OS X']\n",
      "browsers:['other' 'chrome' 'ie' 'safari' 'edge' 'firefox' 'samsung' 'opera'\n",
      " 'palemoon']\n",
      "Mem. usage decreased to 315.73 Mb (21.6% reduction)\n",
      "CPU times: user 1min 3s, sys: 31 s, total: 1min 34s\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>addr1</th>\n",
       "      <th>...</th>\n",
       "      <th>id_30</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18403224</td>\n",
       "      <td>31.953125</td>\n",
       "      <td>4</td>\n",
       "      <td>10409</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>226.0</td>\n",
       "      <td>2</td>\n",
       "      <td>170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>390</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18403263</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4272</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>226.0</td>\n",
       "      <td>2</td>\n",
       "      <td>299.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>390</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18403310</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4476</td>\n",
       "      <td>574.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>226.0</td>\n",
       "      <td>2</td>\n",
       "      <td>472.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>390</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18403310</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>10989</td>\n",
       "      <td>360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2</td>\n",
       "      <td>205.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>390</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18403317</td>\n",
       "      <td>67.937500</td>\n",
       "      <td>4</td>\n",
       "      <td>18018</td>\n",
       "      <td>452.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>117.0</td>\n",
       "      <td>2</td>\n",
       "      <td>264.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>390</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionDT  TransactionAmt  ProductCD  card1  card2  card3  card4  \\\n",
       "0       18403224       31.953125          4  10409  111.0  150.0      4   \n",
       "1       18403263       49.000000          4   4272  111.0  150.0      4   \n",
       "2       18403310      171.000000          4   4476  574.0  150.0      4   \n",
       "3       18403310      285.000000          4  10989  360.0  150.0      4   \n",
       "4       18403317       67.937500          4  18018  452.0  150.0      2   \n",
       "\n",
       "   card5  card6  addr1  ...  id_30  id_31  id_32  id_33  id_34  id_36  id_37  \\\n",
       "0  226.0      2  170.0  ...      4      5   24.0    390      2      2      2   \n",
       "1  226.0      2  299.0  ...      4      5   24.0    390      2      2      2   \n",
       "2  226.0      2  472.0  ...      4      5   24.0    390      2      2      2   \n",
       "3  166.0      2  205.0  ...      4      5   24.0    390      2      2      2   \n",
       "4  117.0      2  264.0  ...      4      5   24.0    390      2      2      2   \n",
       "\n",
       "   id_38  DeviceType  DeviceInfo  \n",
       "0      2           2        2184  \n",
       "1      2           2        2184  \n",
       "2      2           2        2184  \n",
       "3      2           2        2184  \n",
       "4      2           2        2184  \n",
       "\n",
       "[5 rows x 269 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transaction_dataframe = pd.read_csv(test_transaction_data_path)\n",
    "transaction_dataframe = reduce_mem_usage(transaction_dataframe)\n",
    "\n",
    "identity_dataframe = pd.read_csv(test_identity_data_path)\n",
    "identity_dataframe = reduce_mem_usage(identity_dataframe)\n",
    "identity_dataframe = identity_dataframe.rename(\n",
    "    columns={\n",
    "        column: column.replace('-', '_')\n",
    "        for column in identity_dataframe.columns\n",
    "    }\n",
    ")\n",
    "\n",
    "dataframe = transaction_dataframe.merge(identity_dataframe, how='outer')\n",
    "transaction_id_data = dataframe['TransactionID']  # need it for output\n",
    "\n",
    "del transaction_dataframe\n",
    "del identity_dataframe\n",
    "\n",
    "print(f'number of rows in test data: {len(dataframe)}')\n",
    "\n",
    "test_dataframe = preprocess(dataframe)\n",
    "del dataframe\n",
    "\n",
    "test_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do inference on test data and get output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 19s, sys: 583 ms, total: 2min 19s\n",
      "Wall time: 15.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>4.715187e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>8.827032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>4.807896e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>5.349725e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>4.747645e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID       isFraud\n",
       "0        3663549  4.715187e-07\n",
       "1        3663550  8.827032e-07\n",
       "2        3663551  4.807896e-07\n",
       "3        3663552  5.349725e-06\n",
       "4        3663553  4.747645e-07"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prediction = booster.predict(test_dataframe)\n",
    "\n",
    "output_dataframe = pd.DataFrame({\n",
    "    'TransactionID': transaction_id_data,\n",
    "    'isFraud': pd.Series(prediction),\n",
    "})\n",
    "\n",
    "output_dataframe.to_csv(output_dir_path + 'prediction_2.csv', index=False)\n",
    "output_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle result\n",
    "\n",
    "public score: 0.925880  \n",
    "private score: 0.893260 "
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit0656ffb61a14454b8758eedef206058e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}