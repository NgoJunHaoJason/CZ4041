{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do hyperparameter tuning \n",
    "\n",
    "- for Light Gradient Boosting Machine\n",
    "- [reference](https://towardsdatascience.com/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "import joblib\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "\n",
    "import op\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from hyperopt import fmin, hp, tpe, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "model_dir_path = 'models/lgbm/'\n",
    "output_dir_path = 'output/lgbm/'\n",
    "\n",
    "train_transaction_data_path = 'data/train_transaction.csv'\n",
    "train_identity_data_path = 'data/train_identity.csv'\n",
    "test_transaction_data_path = 'data/test_transaction.csv'\n",
    "test_identity_data_path = 'data/test_identity.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define utility function to reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Reduce dataframe size\n",
    "\n",
    "    params:\n",
    "    - df: dataframe to reduce the size of\n",
    "\n",
    "    return:\n",
    "    - dataframe of reduced size\n",
    "    \"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'float128']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float64).min and c_max < np.finfo(np.float64).max:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "                elif c_min > np.finfo(np.float128).min and c_max < np.finfo(np.float128).max:\n",
    "                    df[col] = df[col].astype(np.float128)\n",
    "                    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    if verbose: \n",
    "        print(\n",
    "            'Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(\n",
    "            end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "        ))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list down useless features (known from feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_features = [\n",
    "    'TransactionID',  # not really a feature\n",
    "    'dist2',  # transaction features\n",
    "    'C3',  # C features\n",
    "    'D6', 'D7', 'D8', 'D9', 'D12', 'D13', 'D14',  # D features\n",
    "    'M1',  # M features\n",
    "    'id_07', 'id_08', 'id_18', 'id_21', 'id_22', 'id_23',  # id features\n",
    "    'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_35',  # id features\n",
    "    'V6', 'V8', 'V9', 'V10', 'V11', 'V14', 'V15', 'V16',  # V features\n",
    "    'V18', 'V21', 'V22', 'V27', 'V28', 'V31', 'V32',  # V features\n",
    "    'V41', 'V42', 'V46', 'V50', 'V51', 'V59', 'V65',  # V features\n",
    "    'V68', 'V71', 'V72', 'V79', 'V80', 'V84', 'V85',  # V features\n",
    "    'V88', 'V89', 'V92', 'V93', 'V95', 'V98', 'V101',  # V features\n",
    "    'V104', 'V106', 'V107', 'V108', 'V109', 'V110',  # V features\n",
    "    'V111', 'V112', 'V113', 'V114', 'V116', 'V117',  # V features\n",
    "    'V118', 'V119', 'V120', 'V121', 'V122', 'V123',  # V features \n",
    "    'V125', 'V138', 'V141', 'V142', 'V144', 'V146',  # V features \n",
    "    'V147', 'V148', 'V151', 'V153', 'V154', 'V155',  # V features \n",
    "    'V157', 'V158', 'V159', 'V161', 'V163', 'V164',  # V features \n",
    "    'V166', 'V172', 'V173', 'V174', 'V175', 'V176',  # V features \n",
    "    'V177', 'V178', 'V179', 'V180', 'V181', 'V182',  # V features  \n",
    "    'V183', 'V184', 'V185', 'V186', 'V190', 'V191',  # V features  \n",
    "    'V192', 'V193', 'V194', 'V195', 'V196', 'V197',  # V features  \n",
    "    'V198', 'V199', 'V214', 'V216', 'V220', 'V225',  # V features \n",
    "    'V226', 'V227', 'V230', 'V233', 'V235', 'V236',  # V features  \n",
    "    'V237', 'V238', 'V239', 'V240', 'V241', 'V242',  # V features \n",
    "    'V244', 'V246', 'V247', 'V248', 'V249', 'V250',  # V features \n",
    "    'V252', 'V254', 'V255', 'V269', 'V276', 'V297',  # V features \n",
    "    'V300', 'V302', 'V304', 'V305', 'V325', 'V327',  # V features  \n",
    "    'V328', 'V329', 'V330', 'V334', 'V335', 'V336',  # V features \n",
    "    'V337', 'V338', 'V339',  # V features \n",
    "]\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function to disregard OS versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_os_version(df, verbose: bool=True):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    - df (DataFrame): has id_30 as one of its columns\n",
    "    - verbose (bool): prints information if True\n",
    "\n",
    "    return: dataframe, after os versions have been ignored\n",
    "    \"\"\"\n",
    "    os_list = [\n",
    "        'Android',\n",
    "        'iOS',\n",
    "        'Mac OS X',\n",
    "        'Windows',\n",
    "    ]\n",
    "\n",
    "    for index, operating_system in df.id_30.iteritems():\n",
    "        new_os = 'other'\n",
    "\n",
    "        if isinstance(operating_system, str):\n",
    "            for known_os in os_list:\n",
    "                if known_os in operating_system:\n",
    "                    new_os = known_os\n",
    "                    break\n",
    "\n",
    "        df.at[index, 'id_30'] = new_os\n",
    "\n",
    "    if verbose:\n",
    "        print('operating systems:', df.id_30.unique())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function to disregard browser versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_browser_version(df, verbose: bool=True):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    - df (DataFrame): has id_31 as one of its columns\n",
    "    - verbose (bool): prints information if True\n",
    "\n",
    "    return: dataframe, after browser versions have been ignored\n",
    "    \"\"\"\n",
    "    browser_list = [\n",
    "        'aol',\n",
    "        'chrome',\n",
    "        'chromium',\n",
    "        'comodo',\n",
    "        'cyberfox',\n",
    "        'edge',\n",
    "        'firefox',\n",
    "        'icedragon',\n",
    "        'ie',\n",
    "        'iron',\n",
    "        'maxthon',\n",
    "        'opera',\n",
    "        'palemoon',\n",
    "        'puffin',\n",
    "        'safari',\n",
    "        'samsung',\n",
    "        'seamonkey',\n",
    "        'silk',\n",
    "        'waterfox',\n",
    "    ]\n",
    "\n",
    "    for index, browser in df.id_31.iteritems():\n",
    "        new_browser = 'other'\n",
    "\n",
    "        if isinstance(browser, str):\n",
    "            for known_browser in browser_list:\n",
    "                if known_browser in browser:\n",
    "                    new_browser = known_browser\n",
    "                    break\n",
    "\n",
    "        df.at[index, 'id_31'] = new_browser\n",
    "\n",
    "    if verbose:\n",
    "        print('browsers:', df.id_31.unique())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function for preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, verbose: bool=True):\n",
    "    \"\"\"\n",
    "    Does the following preprocessing steps:\n",
    "    - disregard os versions\n",
    "    - disregard browser versions\n",
    "    - drop useless features\n",
    "    - convert object columns to string columns\n",
    "    - imputation (for numbers, fill with interquartile mean)\n",
    "    - do label encoding for non-numeric values\n",
    "    - reduce memory usage again\n",
    "\n",
    "    params:   \n",
    "    - df (DataFrame): dataframe to preprocess (has columns id_30 and id_31)\n",
    "    - verbose (bool): prints information if True\n",
    "\n",
    "    return: dataframe, preprocessing is complete\n",
    "    \"\"\"\n",
    "    df = df.drop(useless_features, axis=1)\n",
    "    df = ignore_os_version(df, verbose)\n",
    "    df = ignore_browser_version(df, verbose)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column]= df[column].astype(str)\n",
    "            df[column] = le.fit_transform(df[column])\n",
    "        else:\n",
    "            df[column] = df[column].fillna(df[column].quantile().mean())\n",
    "\n",
    "    df = reduce_mem_usage(df, verbose)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function for training LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(training_parameters, num_boost_round=10000):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    classifier = lgb.train(\n",
    "        training_parameters, \n",
    "        train_set=train_data, \n",
    "        num_boost_round=num_boost_round, \n",
    "        valid_sets=[train_data, val_data],\n",
    "        verbose_eval=500,\n",
    "        early_stopping_rounds=500,\n",
    "    )\n",
    "\n",
    "    prediction = classifier.predict(val_features)\n",
    "    auc = roc_auc_score(val_target, prediction)\n",
    "    print(f'auc: {auc}')\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and preprocess training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mem. usage decreased to 542.35 Mb (69.4% reduction)\nMem. usage decreased to 25.86 Mb (42.7% reduction)\nnumber of rows in training data: 590540\noperating systems: ['other' 'Android' 'iOS' 'Mac OS X' 'Windows']\nbrowsers: ['other' 'samsung' 'safari' 'chrome' 'edge' 'firefox' 'ie' 'opera' 'aol'\n 'silk' 'waterfox' 'puffin' 'cyberfox' 'palemoon' 'maxthon' 'iron'\n 'seamonkey' 'comodo' 'chromium' 'icedragon']\nMem. usage decreased to 357.35 Mb (22.1% reduction)\nCPU times: user 1min 14s, sys: 35.9 s, total: 1min 50s\nWall time: 1min 50s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   isFraud  TransactionDT  TransactionAmt  ProductCD  card1  card2  card3  \\\n0        0          86400            68.5          4  13926  361.0  150.0   \n1        0          86401            29.0          4   2755  404.0  150.0   \n2        0          86469            59.0          4   4663  490.0  150.0   \n3        0          86499            50.0          4  18132  567.0  150.0   \n4        0          86506            50.0          1   4497  514.0  150.0   \n\n   card4  card5  card6  ...  id_30  id_31  id_32  id_33  id_34  id_36  id_37  \\\n0      1  142.0      1  ...      4     12   24.0    260      4      2      2   \n1      2  102.0      1  ...      4     12   24.0    260      4      2      2   \n2      4  166.0      2  ...      4     12   24.0    260      4      2      2   \n3      2  117.0      2  ...      4     12   24.0    260      4      2      2   \n4      2  102.0      1  ...      0     16   32.0    164      3      0      1   \n\n   id_38  DeviceType  DeviceInfo  \n0      2           2        1742  \n1      2           2        1742  \n2      2           2        1742  \n3      2           2        1742  \n4      1           1         954  \n\n[5 rows x 270 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isFraud</th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>ProductCD</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card4</th>\n      <th>card5</th>\n      <th>card6</th>\n      <th>...</th>\n      <th>id_30</th>\n      <th>id_31</th>\n      <th>id_32</th>\n      <th>id_33</th>\n      <th>id_34</th>\n      <th>id_36</th>\n      <th>id_37</th>\n      <th>id_38</th>\n      <th>DeviceType</th>\n      <th>DeviceInfo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>86400</td>\n      <td>68.5</td>\n      <td>4</td>\n      <td>13926</td>\n      <td>361.0</td>\n      <td>150.0</td>\n      <td>1</td>\n      <td>142.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>86401</td>\n      <td>29.0</td>\n      <td>4</td>\n      <td>2755</td>\n      <td>404.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>102.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>86469</td>\n      <td>59.0</td>\n      <td>4</td>\n      <td>4663</td>\n      <td>490.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>166.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>86499</td>\n      <td>50.0</td>\n      <td>4</td>\n      <td>18132</td>\n      <td>567.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>117.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>86506</td>\n      <td>50.0</td>\n      <td>1</td>\n      <td>4497</td>\n      <td>514.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>102.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>16</td>\n      <td>32.0</td>\n      <td>164</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>954</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 270 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transaction_dataframe = pd.read_csv(train_transaction_data_path)\n",
    "transaction_dataframe = reduce_mem_usage(transaction_dataframe)\n",
    "\n",
    "identity_dataframe = pd.read_csv(train_identity_data_path)\n",
    "identity_dataframe = reduce_mem_usage(identity_dataframe)\n",
    "\n",
    "dataframe = transaction_dataframe.merge(identity_dataframe, how='outer')\n",
    "\n",
    "del transaction_dataframe\n",
    "del identity_dataframe\n",
    "\n",
    "print(f'number of rows in training data: {len(dataframe)}')\n",
    "dataframe = preprocess(dataframe)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dataframe = dataframe.drop('isFraud', axis=1)\n",
    "is_fraud_data = dataframe['isFraud']\n",
    "\n",
    "del dataframe\n",
    "\n",
    "train_features, val_features, train_target, val_target = train_test_split(\n",
    "    features_dataframe, \n",
    "    is_fraud_data, \n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "del features_dataframe\n",
    "del is_fraud_data\n",
    "\n",
    "train_data = lgb.Dataset(train_features, train_target)\n",
    "val_data = lgb.Dataset(val_features, val_target)\n",
    "\n",
    "del train_features\n",
    "del train_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, n_folds=10):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Tuning\"\"\"\n",
    "    # https://github.com/hyperopt/hyperopt/issues/498#issuecomment-532011953\n",
    "    params['subsample'] = params['boosting_type']['subsample']\n",
    "    boost_type = params['boosting_type']['boosting_type']\n",
    "    del params['boosting_type']\n",
    "    params['boosting_type'] = boost_type\n",
    "    \n",
    "    # Perform n_fold cross validation with hyperparameters\n",
    "    # Use early stopping and evalute based on ROC AUC\n",
    "    cv_results = lgb.cv(\n",
    "        params, \n",
    "        train_data, \n",
    "        nfold=n_folds, \n",
    "        num_boost_round=10000, \n",
    "        early_stopping_rounds=100, \n",
    "        metrics = 'auc', \n",
    "        seed=0,\n",
    "        verbose_eval=500,\n",
    "    )\n",
    "    \n",
    "    # Extract the best score\n",
    "    best_score = max(cv_results['auc-mean'])\n",
    "    \n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'status': hyperopt.STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "space = {\n",
    "    'boosting_type': hp.choice('boosting_type', [\n",
    "        {'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "        {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "        {'boosting_type': 'goss', 'subsample': 1.0},\n",
    "    ]),\n",
    "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 150, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'min_child_samples': scope.int(hp.quniform('min_child_samples', 20, 500, 5)),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "}\n",
    "#     'subsample_for_bin': scope.int(hp.quniform('subsample_for_bin', 20000, 300000, 20000)),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## look at 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'boosting_type': 'gbdt',\n 'class_weight': 'balanced',\n 'colsample_bytree': 0.8267872317892246,\n 'feature_pre_filter': False,\n 'learning_rate': 0.01259173426492532,\n 'min_child_samples': 455,\n 'num_leaves': 52,\n 'reg_alpha': 0.778935788803114,\n 'reg_lambda': 0.2962500770997206,\n 'subsample': 0.8398368225217937}"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# Sample from the full space\n",
    "example = sample(space)\n",
    "\n",
    "# Dictionary get method with default\n",
    "subsample = example['boosting_type'].get('subsample', 1.0)\n",
    "\n",
    "# Assign top-level keys\n",
    "example['boosting_type'] = example['boosting_type']['boosting_type']\n",
    "example['subsample'] = subsample\n",
    "\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0%|          | 0/500 [00:00<?, ?trial/s, best loss=?]job exception: Cannot change feature_pre_filter after constructed Dataset handle.\n\n  0%|          | 0/500 [00:00<?, ?trial/s, best loss=?]\n"
    },
    {
     "output_type": "error",
     "ename": "LightGBMError",
     "evalue": "Cannot change feature_pre_filter after constructed Dataset handle.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ae78c3f69c9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbayes_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/ml_venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         )\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         )\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             )\n\u001b[0;32m--> 894\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-83ad2d0c03d7>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params, n_folds)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_venv/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m     \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m              \u001b[0;34m.\u001b[0m\u001b[0m_set_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m              \u001b[0;34m.\u001b[0m\u001b[0mset_feature_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_venv/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_update_params\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m   1265\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_free_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Cannot change feature_pre_filter after constructed Dataset handle."
     ]
    }
   ],
   "source": [
    "bayes_trials = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    fn=objective, \n",
    "    space=space, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=500, \n",
    "    trials=bayes_trials,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['models/lgbm/lgbm_0.joblib']"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "joblib.dump(lgbm, model_dir_path + 'lgbm_0.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and preprocess test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mem. usage decreased to 472.59 Mb (68.9% reduction)\nMem. usage decreased to 25.44 Mb (42.7% reduction)\nnumber of rows in test data: 506691\noperating systems: ['other' 'Android' 'iOS' 'Windows' 'Mac OS X']\nbrowsers: ['other' 'chrome' 'ie' 'safari' 'edge' 'firefox' 'samsung' 'opera'\n 'palemoon']\nMem. usage decreased to 315.73 Mb (21.6% reduction)\nCPU times: user 1min 4s, sys: 31.6 s, total: 1min 36s\nWall time: 1min 36s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   TransactionDT  TransactionAmt  ProductCD  card1  card2  card3  card4  \\\n0       18403224       31.953125          4  10409  111.0  150.0      4   \n1       18403263       49.000000          4   4272  111.0  150.0      4   \n2       18403310      171.000000          4   4476  574.0  150.0      4   \n3       18403310      285.000000          4  10989  360.0  150.0      4   \n4       18403317       67.937500          4  18018  452.0  150.0      2   \n\n   card5  card6  addr1  ...  id_30  id_31  id_32  id_33  id_34  id_36  id_37  \\\n0  226.0      2  170.0  ...      4      5   24.0    390      2      2      2   \n1  226.0      2  299.0  ...      4      5   24.0    390      2      2      2   \n2  226.0      2  472.0  ...      4      5   24.0    390      2      2      2   \n3  166.0      2  205.0  ...      4      5   24.0    390      2      2      2   \n4  117.0      2  264.0  ...      4      5   24.0    390      2      2      2   \n\n   id_38  DeviceType  DeviceInfo  \n0      2           2        2184  \n1      2           2        2184  \n2      2           2        2184  \n3      2           2        2184  \n4      2           2        2184  \n\n[5 rows x 269 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>ProductCD</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card4</th>\n      <th>card5</th>\n      <th>card6</th>\n      <th>addr1</th>\n      <th>...</th>\n      <th>id_30</th>\n      <th>id_31</th>\n      <th>id_32</th>\n      <th>id_33</th>\n      <th>id_34</th>\n      <th>id_36</th>\n      <th>id_37</th>\n      <th>id_38</th>\n      <th>DeviceType</th>\n      <th>DeviceInfo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18403224</td>\n      <td>31.953125</td>\n      <td>4</td>\n      <td>10409</td>\n      <td>111.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>226.0</td>\n      <td>2</td>\n      <td>170.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18403263</td>\n      <td>49.000000</td>\n      <td>4</td>\n      <td>4272</td>\n      <td>111.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>226.0</td>\n      <td>2</td>\n      <td>299.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18403310</td>\n      <td>171.000000</td>\n      <td>4</td>\n      <td>4476</td>\n      <td>574.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>226.0</td>\n      <td>2</td>\n      <td>472.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18403310</td>\n      <td>285.000000</td>\n      <td>4</td>\n      <td>10989</td>\n      <td>360.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>166.0</td>\n      <td>2</td>\n      <td>205.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18403317</td>\n      <td>67.937500</td>\n      <td>4</td>\n      <td>18018</td>\n      <td>452.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>117.0</td>\n      <td>2</td>\n      <td>264.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 269 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transaction_dataframe = pd.read_csv(test_transaction_data_path)\n",
    "transaction_dataframe = reduce_mem_usage(transaction_dataframe)\n",
    "\n",
    "identity_dataframe = pd.read_csv(test_identity_data_path)\n",
    "identity_dataframe = reduce_mem_usage(identity_dataframe)\n",
    "identity_dataframe = identity_dataframe.rename(\n",
    "    columns={\n",
    "        column: column.replace('-', '_')\n",
    "        for column in identity_dataframe.columns\n",
    "    }\n",
    ")\n",
    "\n",
    "dataframe = transaction_dataframe.merge(identity_dataframe, how='outer')\n",
    "transaction_id_data = dataframe['TransactionID']  # need it for output\n",
    "\n",
    "del transaction_dataframe\n",
    "del identity_dataframe\n",
    "\n",
    "print(f'number of rows in test data: {len(dataframe)}')\n",
    "\n",
    "test_dataframe = preprocess(dataframe)\n",
    "del dataframe\n",
    "\n",
    "test_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do inference on test data and get output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 3min 28s, sys: 817 ms, total: 3min 28s\nWall time: 22.3 s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   TransactionID   isFraud\n0        3663549  0.000080\n1        3663550  0.000006\n2        3663551  0.000025\n3        3663552  0.000388\n4        3663553  0.000698",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionID</th>\n      <th>isFraud</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3663549</td>\n      <td>0.000080</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3663550</td>\n      <td>0.000006</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3663551</td>\n      <td>0.000025</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3663552</td>\n      <td>0.000388</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3663553</td>\n      <td>0.000698</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prediction = lgbm.predict(test_dataframe)\n",
    "\n",
    "output_dataframe = pd.DataFrame({\n",
    "    'TransactionID': transaction_id_data,\n",
    "    'isFraud': pd.Series(prediction),\n",
    "})\n",
    "\n",
    "output_dataframe.to_csv(output_dir_path + 'prediction_0.csv', index=False)\n",
    "output_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle result\n",
    "\n",
    "public score: 0.906242  \n",
    "private score: 0.861183  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit0656ffb61a14454b8758eedef206058e",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}